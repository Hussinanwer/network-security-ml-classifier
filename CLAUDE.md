# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

This is a Network Security machine learning project focused on multiclass classification of network traffic. The project analyzes network traffic patterns to classify different types of network behavior using various ML algorithms.

## Dataset

**File**: `network_traffic_multiclass_dataset.csv`
- 2073 samples with 36 features
- Target variable: `label` (3 classes: 0, 1, 2)
- Features include network packet characteristics (IPs, ports, protocols, packet sizes, timing, flags, etc.)
- No missing values in the dataset

### Key Features
- IP addresses (src_ip, dst_ip): Converted to integers using `socket.inet_aton`
- Protocol: Encoded using LabelEncoder
- Port indicators: is_port_22, is_port_6200, is_ftp_port, is_ftp_data_port
- Packet statistics: counts, sizes, timing (IAT - Inter-Arrival Time)
- TCP flags: syn_count, ack_count, fin_count, rst_count, psh_count, urg_count
- Flow metrics: forward/backward packets/bytes, ratios, rates

## Data Processing Pipeline

The notebook follows this workflow:

1. **Data Loading & Exploration**: Load CSV, check shape, info, missing values
2. **Categorical Encoding** (Cell 4): Use LabelEncoder for src_ip, dst_ip, and protocol fields
   - src_ip: Encoded as 0, 1, 2 (3 unique values)
   - dst_ip: Encoded as 0, 1, 2, 3 (4 unique values)
   - protocol: Encoded as 0, 1 (2 unique values - TCP, UDP)
3. **Feature Removal** (Cell 7): Remove 5 features total
   - **Zero variance** (1 unique value): urg_count, is_ftp_data_port
   - **Leaky indicator**: is_port_6200 (perfect attack indicator)
   - **Encoded categoricals**: src_ip, dst_ip (removed after encoding for better generalization)
   - **Result**: 31 features (from 35 original minus 4 removed - protocol kept)
4. **Train-Test Split**: 80/20 split with stratification
5. **Scaling**: StandardScaler on features
6. **Feature Selection**: ANOVA F-test (SelectKBest) to select top 15 features
7. **Model Training & Evaluation**: Multiple classifiers tested

**IMPORTANT**: The notebook uses LabelEncoder for IP addresses, NOT socket.inet_aton(). This encodes IPs as simple sequential integers (0, 1, 2...) based on unique values. The encoded src_ip and dst_ip are then REMOVED before training (cell 7) for better generalization.

### Final Feature Set
- **After preprocessing**: 31 features (35 original - 4 removed, protocol encoded kept)
- **After ANOVA selection**: 15 features (selected by F-test based on correlation with target)

## Models Implemented

### 1. Logistic Regression
- Default parameters with LBFGS solver
- Note: May show convergence warning - increase max_iter if needed
- Test Accuracy: ~87.5%

### 2. Random Forest Classifier
- n_estimators=3 (deliberately small for quick testing)
- Test Accuracy: 100% (may indicate overfitting with only 3 trees)
- Perfect performance on test set

### 3. SVM (Support Vector Machine)
- Kernel: RBF
- C=4, gamma='scale'
- Test Accuracy: ~72.3%

## Running the Notebook

**Environment**: Jupyter Notebook with Python 3

**Required Libraries**:
```python
numpy, pandas, matplotlib, seaborn, sklearn, imblearn
```

**Execute in order**: The notebook cells must be run sequentially as they build on each other's state (feature removal affects subsequent steps).

## Important Notes

- The notebook includes interactive input prompts for feature removal decisions - these need user input
- SMOTE is applied only to training data to prevent data leakage
- StandardScaler is fit on training data and transformed on both train/test
- Label distribution before SMOTE: Class 0 (632), Class 2 (553), Class 1 (473)
- After SMOTE: All classes balanced to 632 samples

## Class Labels

The dataset has 3 classes (0, 1, 2):
- **Class 0**: Normal - Regular network traffic, no threats detected
- **Class 1**: vsftpd Backdoor - MALICIOUS backdoor attack exploiting vsftpd vulnerability (CVE-2011-2523)
- **Class 2**: SSH Brute Force - MALICIOUS automated password guessing attacks on SSH

**IMPORTANT**: Label 1 (vsftpd Backdoor) is a MALICIOUS attack, not benign FTP traffic!

## Feature Engineering Insights

Key discriminative features (by target correlation):
- **src_ip**: Strongest predictor (-0.878) - suggests traffic patterns differ by source
- **bytes_per_second**: High negative correlation (-0.761)
- **packets_per_second**: Negative correlation (-0.562)
- **backward_bytes**: Positive correlation (0.534)
- **is_port_22**: Positive correlation (0.400)
- **is_ftp_port**: Negative correlation (-0.466)

## Production Deployment

This project has been converted to a production-ready system with REST API and web interface.

### Project Structure

```
.
├── api/
│   ├── app.py              # FastAPI application
│   └── __init__.py
├── models/                  # Saved models (generated by train.py)
│   ├── rf_model.pkl        # Random Forest (primary model)
│   ├── lr_model.pkl        # Logistic Regression
│   ├── svm_model.pkl       # SVM
│   ├── dt_model.pkl        # Decision Tree
│   ├── nb_model.pkl        # Naive Bayes
│   ├── scaler.pkl          # StandardScaler
│   ├── label_encoders.pkl  # LabelEncoders for categorical features
│   ├── preprocessor.pkl    # Complete preprocessor
│   ├── feature_selector.pkl # ANOVA SelectKBest (k=15)
│   └── model_metadata.pkl  # Model performance metrics
├── Scripts/
│   └── pcap_to_csv_multiclass.py  # Original PCAP conversion script
├── tests/                   # Test suite
│   ├── test_preprocessing.py
│   ├── test_api.py
│   └── test_data/
├── dashboard.py             # Streamlit web interface
├── train.py                 # Model training script
├── preprocessing.py         # Preprocessing pipeline module
├── pcap_converter.py        # PCAP to DataFrame converter (for dashboard)
├── config.py                # Configuration settings
├── run_api.py               # API launcher
├── run_dashboard.py         # Dashboard launcher
├── CLAUDE.md                # Project documentation
└── requirements.txt         # Dependencies
```

### Training Models

**IMPORTANT:** Always run `train.py` first to generate model files:

```bash
python train.py
```

This script:
- Loads the dataset
- Applies the complete preprocessing pipeline
- Trains Random Forest (n_estimators=100 for production), Logistic Regression, and SVM
- Saves all models and metadata to `models/` directory
- Displays performance metrics

**Production model:** Random Forest with 100 trees (not 3 as in notebook)

### Preprocessing Pipeline

The preprocessing is encapsulated in `preprocessing.py`:

- **NetworkTrafficPreprocessor**: Main class that handles the complete pipeline
- **fit()**: Fit on training data (learns encoders, scalers)
- **transform()**: Transform new data using fitted components
- **fit_transform()**: Combined fit and transform

The preprocessing order EXACTLY matches the notebook:
1. **Categorical Encoding**: LabelEncoder for src_ip, dst_ip, protocol
2. **Feature Removal** (5 features):
   - is_ftp_data_port (zero variance)
   - urg_count (zero variance)
   - src_ip (encoded categorical, removed for generalization)
   - dst_ip (encoded categorical, removed for generalization)
   - is_port_6200 (leaky indicator)
3. **Scaling**: StandardScaler on all 31 remaining features
4. **Feature Selection** (in train.py): ANOVA F-test SelectKBest (k=15)

**CRITICAL**:
- IP addresses are encoded using LabelEncoder (sequential integers 0,1,2...), NOT socket.inet_aton()!
- src_ip and dst_ip are REMOVED after encoding (notebook cell 7) for better generalization
- Final feature count: 31 (before feature selection), then 15 (after ANOVA)

### REST API

**File:** `api/app.py`

**Endpoints:**
- `POST /predict` - Single prediction
- `POST /predict/batch` - Batch predictions from CSV
- `GET /health` - Health check
- `GET /model-info` - Model metadata

**Run:**
```bash
python run_api.py
# or
uvicorn api.app:app --host 0.0.0.0 --port 8000
```

**Access:** http://localhost:8000/docs (interactive documentation)

### Streamlit Dashboard

**File:** `dashboard.py`

**Features:**
- Manual feature input form
- **CSV upload** for batch predictions
- **PCAP upload** for batch predictions (automatically extracts network flows)
- Real-time predictions with confidence scores
- Confusion matrix visualization
- Download prediction results as CSV

**Supported File Types:**
- CSV files with 35 features (template available in dashboard)
- PCAP files (.pcap, .pcapng) - automatically converted to features

**Run:**
```bash
python run_dashboard.py
# or
streamlit run dashboard.py --server.port=8501
```

**Access:** http://localhost:8501

**PCAP Processing:**
When uploading PCAP files, the dashboard:
1. Extracts network flows from packets (using pyshark)
2. Calculates all 35 features per flow
3. Runs predictions on each flow
4. Displays results with confidence scores

Each flow represents a unique bidirectional connection between source and destination IPs/ports.

### Docker Deployment

**Files:** `Dockerfile`, `docker-compose.yml`

**Multi-stage build:**
- `train`: Training image
- `api`: FastAPI service
- `dashboard`: Streamlit service

**Deploy:**
```bash
# Train models
docker-compose run train

# Start services
docker-compose up -d api dashboard
```

### Configuration

**File:** `config.py`

Environment variables (`.env`):
- `API_HOST`, `API_PORT`: API server settings
- `DASHBOARD_PORT`: Dashboard port
- `RF_N_ESTIMATORS`: Random Forest tree count
- `LOG_LEVEL`: Logging level

### Testing

**Run tests:**
```bash
pytest tests/ -v
```

**Test files:**
- `test_preprocessing.py`: Unit tests for preprocessing functions
- `test_api.py`: Integration tests for API endpoints

### Common Development Tasks

**Retrain models:**
```bash
python train.py
```

**Run API locally:**
```bash
python run_api.py
```

**Run dashboard locally:**
```bash
python run_dashboard.py
```

**Run tests:**
```bash
pytest tests/ -v
```

**Test single endpoint:**
```bash
pytest tests/test_api.py::TestPredictEndpoint::test_predict_success -v
```

### Critical Implementation Notes

1. **Preprocessing order matters:** The exact sequence from the notebook must be maintained
2. **SMOTE only for training:** Never apply SMOTE to production inference data
3. **Feature order:** API must receive features in the same order as training
4. **Model loading:** Models are loaded on API startup (see `@app.on_event("startup")`)
5. **Error handling:** All API endpoints have comprehensive error handling

### API Input Format

All 35 original features must be provided (excluding label). The API automatically applies the preprocessing pipeline. See `API.md` for complete field descriptions.

### Model Performance (Production)

| Model | Test Accuracy | F1 Score |
|-------|---------------|----------|
| Random Forest (100 trees) | 100.0% | 100.0% |
| Logistic Regression | 87.5% | 87.5% |
| SVM | 72.3% | 72.1% |

**Primary model:** Random Forest is used for all predictions due to superior performance.
